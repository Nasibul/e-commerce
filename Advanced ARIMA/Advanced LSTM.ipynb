{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_addons as tfa\n",
    "import pickle\n",
    "from datetime import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_squared_log_error, mean_absolute_percentage_error\n",
    "import matplotlib.pyplot as plt\n",
    "import keras_tuner\n",
    "import warnings\n",
    "import calendar\n",
    "import collections.abc\n",
    "collections.Iterable = collections.abc.Iterable\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deeper Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1515, 1808, 1)\n",
      "(169, 1808, 1)\n",
      "(1515, 1808, 1)\n",
      "(169, 1808, 1)\n"
     ]
    }
   ],
   "source": [
    "X = pd.concat([exog, train], axis=1)\n",
    "Y = X.shift(-1, fill_value=0)\n",
    "X_train, X_test, y_train, y_test , X_test_copy, X_test_index = data_prep(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = keras.models.Sequential([\n",
    "    keras.layers.LSTM(50, return_sequences=True, input_shape=[X_train.shape[1], X_train.shape[2]]),\n",
    "    keras.layers.LSTM(50, return_sequences=True),\n",
    "    keras.layers.LSTM(50, return_sequences=True),\n",
    "    keras.layers.LSTM(50, return_sequences=True),\n",
    "    keras.layers.LSTM(50, return_sequences=True),\n",
    "    keras.layers.LSTM(50, return_sequences=True),\n",
    "    keras.layers.Dense(1, activation='relu')\n",
    "])\n",
    "models['model1'] = {'model': model1,\n",
    "                    'params': {}\n",
    "                    }\n",
    "models['model2'] = {'model': 'funk',\n",
    "                    'params': {}\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.sequential.Sequential object at 0x7f2d0db47400>\n",
      "funk\n"
     ]
    }
   ],
   "source": [
    "for i in models:\n",
    "    print(models[i]['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'funk'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models['model2']['model']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Layer Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([exog, train], axis=1)\n",
    "Y = X.shift(-1, fill_value=0)\n",
    "X_train, X_test, y_train, y_test , X_test_copy, X_test_index = data_prep(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = keras.models.Sequential([\n",
    "    keras.layers.RNN(tfa.rnn.LayerNormLSTMCell(100, dropout=0.1, recurrent_dropout=0.1), return_sequences=True, input_shape=[X_train.shape[1], X_train.shape[2]]),\n",
    "    keras.layers.Dense(1, activation='relu')\n",
    "])\n",
    "pred = predict(lstm, X_train, y_train, X_test, X_test_copy, X_test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare(X_test_copy.iloc[:, -1792:], pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypertuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train\n",
    "Y = train.shift(-1, fill_value=0)\n",
    "X_train, X_test, y_train, y_test, X_test_copy, X_test_index = data_prep(X, Y)\n",
    "X_train_mini = X_train[:150, :]\n",
    "y_train_mini = y_train[:150, :]\n",
    "X_val_mini = X_train[151:160, :]\n",
    "y_val_mini = y_train[151:160, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_model(hp):\n",
    "    lstm = keras.models.Sequential([\n",
    "    keras.layers.LSTM(hp.Choice('units', [i*10 for i in range(1, 201)]), return_sequences=True, input_shape=[X_train.shape[1], X_train.shape[2]]),\n",
    "    keras.layers.Dense(1, activation='relu')\n",
    "    ])\n",
    "    lstm.compile(loss=keras.losses.MeanSquaredLogarithmicError(), optimizer=tf.keras.optimizers.Adam(hp.Choice('learning_rate', values=np.linspace(0.0, 0.01, 50).tolist())))\n",
    "    return lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = keras_tuner.RandomSearch(dummy_model, objective='val_loss', max_trials=200)\n",
    "tuner.search(X_train_mini, y_train_mini, epochs=10, validation_data=(X_val_mini, y_val_mini))\n",
    "tuner.get_best_hyperparameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = {}\n",
    "model2 = {}\n",
    "model3 = {}\n",
    "\n",
    "tuning1 = {\n",
    "    \"batch_size\": [32, 64, 128],\n",
    "    \"epochs\": [10, 20, 30],\n",
    "    \"optimizer\": [\"Adam\", \"SGD\"],\n",
    "}\n",
    "tuning2 = {}\n",
    "tuning3 = {}\n",
    "\n",
    "experiment_loop(\n",
    "    models=[model1, model2, model3],\n",
    "    tuning=[tuning1, tuning2, tuning3],\n",
    ")\n",
    "\n",
    "\n",
    "def test_model_valid():\n",
    "    # test model is valid\n",
    "    # test all param choices\n",
    "    # training and prediction forward and backward pass run correctly\n",
    "    pass\n",
    "\n",
    "def _tune():\n",
    "    pass \n",
    "\n",
    "def _train_full_set():\n",
    "    # verbose off\n",
    "    pass\n",
    "\n",
    "def _predict():\n",
    "    pass\n",
    "\n",
    "def _plot_losses():\n",
    "    # loss comparison between models\n",
    "    pass\n",
    "\n",
    "def _plot_y_pred_vs_y():\n",
    "    # comparing a massively reduces subset of data\n",
    "    # comparing models\n",
    "    pass\n",
    "\n",
    "def experiment_loop(\n",
    "    models: list,\n",
    "    tuning: list,\n",
    "):\n",
    "    x_data = pd.DataFrame()\n",
    "    y_data = pd.DataFrame()\n",
    "\n",
    "\n",
    "    losses = [] # list[list]\n",
    "    boards = []\n",
    "    y_preds = []\n",
    "    pred_metrics = []\n",
    "    for i, model in enumerate(models):\n",
    "        # 1. tune\n",
    "        # reduce data size for tuning\n",
    "        # hyperparam tune yields best params for each model\n",
    "        _tune(model, tuning[i])\n",
    "        print(f\"best model params for {model_name} are {best_params}\")\n",
    "\n",
    "        # 2. train\n",
    "        trained_model, loss_arr = _train_full_set(model, best_params)\n",
    "        losses.append(loss_arr)\n",
    "        other_metric = {\n",
    "            \"accuracy\": 0.9,\n",
    "            \"r2\": 0.8,\n",
    "        }\n",
    "        other_metrics.append(other_metric)\n",
    "        boards.append(board_path)\n",
    "\n",
    "        # 3. predict\n",
    "        y_pred = _predict(trained_model, x_holdout)\n",
    "        y_preds.append(y_pred)\n",
    "        pred_metric = {\n",
    "            \"accuracy\": 0.9,\n",
    "            \"r2\": 0.8,\n",
    "        }\n",
    "        pred_metrics.append(pred_metric)\n",
    "\n",
    "    _plot_losses(losses)\n",
    "    _plot_metrics(other_metrics)\n",
    "    _plot_y_pred_vs_y(y_preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
