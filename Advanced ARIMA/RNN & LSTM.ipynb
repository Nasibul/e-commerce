{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-21 17:09:37.980391: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-21 17:09:38.576436: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-21 17:09:38.576507: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-21 17:09:38.576518: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/nasibul/.local/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_addons as tfa\n",
    "import pickle\n",
    "from datetime import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_squared_log_error, mean_absolute_percentage_error\n",
    "import matplotlib.pyplot as plt\n",
    "import keras_tuner\n",
    "import warnings\n",
    "import calendar\n",
    "import collections.abc\n",
    "collections.Iterable = collections.abc.Iterable\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Ingestion and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train\n",
    "Y = train.shift(-1, fill_value=0)\n",
    "X_train, X_test, y_train, y_test, X_test_copy, X_test_index = data_prep(X, Y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(100, return_sequences=True, input_shape=[X_train.shape[1], X_train.shape[2]]),\n",
    "    keras.layers.SimpleRNN(100, return_sequences=True),\n",
    "    keras.layers.SimpleRNN(100, return_sequences=True),\n",
    "    keras.layers.Dense(1, activation='relu')\n",
    "])\n",
    "pred_rnn = predict(rnn, X_train, y_train, X_test, X_test_copy, X_test_index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = pd.DataFrame()\n",
    "for feature in train.columns:\n",
    "    for step in range(1, 17):\n",
    "        Y[f'{feature}_step_ahead_{step}'] = train[feature].shift(-step, fill_value=0)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.10, random_state=5, shuffle=False)\n",
    "X_test_copy = X_test\n",
    "X_test_index = X_test.index\n",
    "X_train = X_train.values.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = X_test.values.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "y_train = y_train.values.reshape(y_train.shape[0], y_train.shape[1], 16)\n",
    "y_test = y_test.values.reshape(y_test.shape[0], y_test.shape[1], 16)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(100, return_sequences=True, input_shape=[X_train.shape[1], X_train.shape[2]]),\n",
    "    keras.layers.SimpleRNN(100, return_sequences=True),\n",
    "    keras.layers.SimpleRNN(100, return_sequences=True),\n",
    "    keras.layers.Dense(16)\n",
    "])\n",
    "rnn.compile(loss=keras.losses.MeanSquaredLogarithmicError(), optimizer=tf.keras.optimizers.Adam())\n",
    "rnn.summary()\n",
    "rnn.fit(X_train, y_train, epochs=10, callbacks=[es])\n",
    "pred_rnn = abs(rnn.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.DataFrame(pred_rnn[168].T, columns=X.columns, index=test.index.unique())\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = []\n",
    "sales = []\n",
    "for i in test.id:\n",
    "    row = test[test['id'] == i]\n",
    "    column = f\"{row['store_nbr'][0]}_{row['family'][0].replace('/', '_')}\"\n",
    "    value = pred[column][pred.index == row.index[0]][0]\n",
    "    # The info from the ID row is taken and used to form a variable called column. \n",
    "    # This column variable refers to the correct store in the dataframe and the equality check on the indexes refer to the proper dates lining up.\n",
    "    id.append(i)\n",
    "    sales.append(value)\n",
    "rnn_submission = pd.DataFrame({'id': id, 'sales': sales})\n",
    "rnn_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_submission.to_csv('RNN_submission.csv', header=True, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train\n",
    "Y = train.shift(-1, fill_value=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.10, random_state=5, shuffle=False)\n",
    "X_test_copy = X_test\n",
    "X_test_index = X_test.index\n",
    "X_train = X_train.values.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = X_test.values.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "y_train = y_train.values.reshape(y_train.shape[0], 1782, 1)\n",
    "y_test = y_test.values.reshape(y_test.shape[0], 1782, 1)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = keras.models.Sequential([\n",
    "    keras.layers.LSTM(100, return_sequences=True, input_shape=[X_train.shape[1], X_train.shape[2]]),\n",
    "    keras.layers.LSTM(100, return_sequences=True),\n",
    "    keras.layers.LSTM(100, return_sequences=True),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "lstm.compile(loss=keras.losses.MeanSquaredLogarithmicError(), optimizer=tf.keras.optimizers.Adam())\n",
    "lstm.summary()\n",
    "lstm.fit(X_train, y_train, epochs=100, callbacks=[es])\n",
    "pred_lstm = abs(lstm.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred_lstm.shape)\n",
    "pred_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lstm = pred_lstm.reshape(169, 1782)\n",
    "pred = pd.DataFrame(pred_lstm, columns=X.columns, index=X_test_index)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare('1_AUTOMOTIVE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare('1_BABY CARE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare('1_BEAUTY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare('1_BEVERAGES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare('1_BOOKS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare('1_BREAD_BAKERY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare('1_CELEBRATION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare('1_CLEANING')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare('1_DAIRY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare('1_DELI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare('1_EGGS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare('1_FROZEN FOODS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare('1_GROCERY I')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare('1_GROCERY II')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare('1_HARDWARE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare('1_HOME AND KITCHEN I')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare('1_HOME AND KITCHEN II')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare('1_HOME APPLIANCES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare('1_HOME CARE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare('1_LADIESWEAR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare('1_LAWN AND GARDEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare('1_LINGERIE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare('1_LIQUOR,WINE,BEER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = list(zip([i+1 for i in range(len(train.columns))], train.columns))\n",
    "col"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = pd.DataFrame()\n",
    "for feature in train.columns:\n",
    "    for step in range(1, 17):\n",
    "        Y[f'{feature}_step_ahead_{step}'] = train[feature].shift(-step, fill_value=0)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.10, random_state=5, shuffle=False)\n",
    "X_test_copy = X_test\n",
    "X_test_index = X_test.index\n",
    "X_train = X_train.values.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = X_test.values.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "y_train = y_train.values.reshape(y_train.shape[0], 1782, 16)\n",
    "y_test = y_test.values.reshape(y_test.shape[0], 1782, 16)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = keras.models.Sequential([\n",
    "    keras.layers.LSTM(100, return_sequences=True, input_shape=[X_train.shape[1], X_train.shape[2]]),\n",
    "    keras.layers.LSTM(100, return_sequences=True),\n",
    "    keras.layers.LSTM(100, return_sequences=True),\n",
    "    keras.layers.Dense(16)\n",
    "])\n",
    "lstm.compile(loss=keras.losses.MeanSquaredLogarithmicError(), optimizer=tf.keras.optimizers.Adam())\n",
    "lstm.summary()\n",
    "lstm.fit(X_train, y_train, epochs=100, callbacks=[es])\n",
    "pred_lstm = abs(lstm.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.DataFrame(pred_lstm[168].T, columns=X.columns, index=test.index.unique())\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = []\n",
    "sales = []\n",
    "for i in test.id:\n",
    "    row = test[test['id'] == i]\n",
    "    column = f\"{row['store_nbr'][0]}_{row['family'][0].replace('/', '_')}\"\n",
    "    value = pred[column][pred.index == row.index[0]][0]\n",
    "    # The info from the ID row is taken and used to form a variable called column. \n",
    "    # This column variable refers to the correct store in the dataframe and the equality check on the indexes refer to the proper dates lining up.\n",
    "    id.append(i)\n",
    "    sales.append(value)\n",
    "lstm_submission = pd.DataFrame({'id': id, 'sales': sales})\n",
    "lstm_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_submission.to_csv('LSTM_submission.csv', header=True, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Experimentation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exog as X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = exog\n",
    "Y = train\n",
    "X_train, X_test, y_train, y_test, X_test_copy, X_test_index = data_prep(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/fit/\" + dt.now().strftime('%m/%d/%Y %-I:%M:%S %p')\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = keras.models.Sequential([\n",
    "    keras.layers.LSTM(100, return_sequences=True, input_shape=[None, X_train.shape[2]]),\n",
    "    keras.layers.LSTM(100, return_sequences=True),\n",
    "    keras.layers.LSTM(100, return_sequences=True),\n",
    "    keras.layers.LSTM(100, return_sequences=True),\n",
    "    keras.layers.Dense(1, activation='relu')\n",
    "])\n",
    "pred = predict(lstm, X_train, y_train, X_test, X_test_copy, X_test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred_lstm.shape)\n",
    "pred_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lstm = pred_lstm.reshape(169, 1782)\n",
    "pred = pd.DataFrame(pred_lstm, columns=Y.columns, index=y_test_index)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare('1_AUTOMOTIVE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare('1_CLEANING')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare('1_DAIRY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare('1_DELI')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exog concatenated with train as X"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One LSTM cell for each time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([exog, train], axis=1)\n",
    "Y = X.shift(-1, fill_value=0)\n",
    "X_train, X_test, y_train, y_test , X_test_copy, X_test_index = data_prep(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = keras.models.Sequential([\n",
    "    keras.layers.LSTM(X.shape[1], return_sequences=True, input_shape=[X_train.shape[1], X_train.shape[2]]),\n",
    "    keras.layers.Dense(1, activation='relu')\n",
    "])\n",
    "lstm.compile(loss=keras.losses.MeanSquaredLogarithmicError(), optimizer=tf.keras.optimizers.Adam())\n",
    "lstm.summary()\n",
    "pred = predict(lstm, X_train, y_train, X_test, X_test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare(X_test_copy.iloc[:, -1782:],pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Triple layer of 100 cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exog = pickle.load(open('exog.pkl', 'rb'))\n",
    "X = pd.concat([exog, train], axis=1)\n",
    "Y = X.shift(-1, fill_value=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.10, random_state=5, shuffle=False)\n",
    "X_test_copy = X_test\n",
    "X_test_index = X_test.index\n",
    "X_train = X_train.values.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = X_test.values.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "y_train = y_train.values.reshape(y_train.shape[0], y_train.shape[1], 1)\n",
    "y_test = y_test.values.reshape(y_test.shape[0], y_test.shape[1], 1)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = keras.models.Sequential([\n",
    "    keras.layers.LSTM(100, return_sequences=True, input_shape=[X_train.shape[1], X_train.shape[2]]),\n",
    "    keras.layers.LSTM(100, return_sequences=True),\n",
    "    keras.layers.LSTM(100, return_sequences=True),\n",
    "    keras.layers.Dense(1, activation='relu')\n",
    "])\n",
    "lstm.compile(loss=keras.losses.MeanSquaredLogarithmicError(), optimizer=tf.keras.optimizers.Adam())\n",
    "lstm.summary()\n",
    "lstm.fit(X_train, y_train, epochs=200, callbacks=[es])\n",
    "pred_lstm = lstm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred_lstm.shape)\n",
    "pred_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lstm = pred_lstm.reshape(X_test.shape[0], X_test.shape[1])\n",
    "pred = pd.DataFrame(pred_lstm, columns=X.columns, index=X_test_index)\n",
    "pred = pred.iloc[:, -1782:]\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare('1_AUTOMOTIVE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare('1_BABY CARE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare('1_BEAUTY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare('1_BEVERAGES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare('1_BOOKS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare('1_BREAD_BAKERY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare('1_CELEBRATION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare('1_CLEANING')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare('1_DAIRY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare('1_DELI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare('1_EGGS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare('1_FROZEN FOODS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare('1_GROCERY I')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare('1_GROCERY II')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare('1_HARDWARE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare('1_HOME AND KITCHEN I')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare('1_HOME AND KITCHEN II')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare('1_HOME APPLIANCES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare('1_HOME CARE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare('1_LADIESWEAR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare('1_LAWN AND GARDEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare('1_LINGERIE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare('1_LIQUOR,WINE,BEER')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Another Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dcoilwtico_step_ahead_1</th>\n",
       "      <th>dcoilwtico_step_ahead_2</th>\n",
       "      <th>dcoilwtico_step_ahead_3</th>\n",
       "      <th>dcoilwtico_step_ahead_4</th>\n",
       "      <th>dcoilwtico_step_ahead_5</th>\n",
       "      <th>dcoilwtico_step_ahead_6</th>\n",
       "      <th>dcoilwtico_step_ahead_7</th>\n",
       "      <th>dcoilwtico_step_ahead_8</th>\n",
       "      <th>dcoilwtico_step_ahead_9</th>\n",
       "      <th>dcoilwtico_step_ahead_10</th>\n",
       "      <th>...</th>\n",
       "      <th>54_SEAFOOD_step_ahead_7</th>\n",
       "      <th>54_SEAFOOD_step_ahead_8</th>\n",
       "      <th>54_SEAFOOD_step_ahead_9</th>\n",
       "      <th>54_SEAFOOD_step_ahead_10</th>\n",
       "      <th>54_SEAFOOD_step_ahead_11</th>\n",
       "      <th>54_SEAFOOD_step_ahead_12</th>\n",
       "      <th>54_SEAFOOD_step_ahead_13</th>\n",
       "      <th>54_SEAFOOD_step_ahead_14</th>\n",
       "      <th>54_SEAFOOD_step_ahead_15</th>\n",
       "      <th>54_SEAFOOD_step_ahead_16</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>93.14</td>\n",
       "      <td>92.97</td>\n",
       "      <td>93.12</td>\n",
       "      <td>93.12</td>\n",
       "      <td>93.20</td>\n",
       "      <td>93.20</td>\n",
       "      <td>93.21</td>\n",
       "      <td>93.08</td>\n",
       "      <td>93.81</td>\n",
       "      <td>93.60</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>92.97</td>\n",
       "      <td>93.12</td>\n",
       "      <td>93.12</td>\n",
       "      <td>93.20</td>\n",
       "      <td>93.20</td>\n",
       "      <td>93.21</td>\n",
       "      <td>93.08</td>\n",
       "      <td>93.81</td>\n",
       "      <td>93.60</td>\n",
       "      <td>93.60</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>93.12</td>\n",
       "      <td>93.12</td>\n",
       "      <td>93.20</td>\n",
       "      <td>93.20</td>\n",
       "      <td>93.21</td>\n",
       "      <td>93.08</td>\n",
       "      <td>93.81</td>\n",
       "      <td>93.60</td>\n",
       "      <td>93.60</td>\n",
       "      <td>94.27</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>93.12</td>\n",
       "      <td>93.20</td>\n",
       "      <td>93.20</td>\n",
       "      <td>93.21</td>\n",
       "      <td>93.08</td>\n",
       "      <td>93.81</td>\n",
       "      <td>93.60</td>\n",
       "      <td>93.60</td>\n",
       "      <td>94.27</td>\n",
       "      <td>94.27</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-05</th>\n",
       "      <td>93.20</td>\n",
       "      <td>93.20</td>\n",
       "      <td>93.21</td>\n",
       "      <td>93.08</td>\n",
       "      <td>93.81</td>\n",
       "      <td>93.60</td>\n",
       "      <td>93.60</td>\n",
       "      <td>94.27</td>\n",
       "      <td>94.27</td>\n",
       "      <td>93.26</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-11</th>\n",
       "      <td>48.81</td>\n",
       "      <td>47.59</td>\n",
       "      <td>47.59</td>\n",
       "      <td>47.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-12</th>\n",
       "      <td>47.59</td>\n",
       "      <td>47.59</td>\n",
       "      <td>47.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-13</th>\n",
       "      <td>47.59</td>\n",
       "      <td>47.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-14</th>\n",
       "      <td>47.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-15</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1684 rows × 28928 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            dcoilwtico_step_ahead_1  dcoilwtico_step_ahead_2  \\\n",
       "date                                                           \n",
       "2013-01-01                    93.14                    92.97   \n",
       "2013-01-02                    92.97                    93.12   \n",
       "2013-01-03                    93.12                    93.12   \n",
       "2013-01-04                    93.12                    93.20   \n",
       "2013-01-05                    93.20                    93.20   \n",
       "...                             ...                      ...   \n",
       "2017-08-11                    48.81                    47.59   \n",
       "2017-08-12                    47.59                    47.59   \n",
       "2017-08-13                    47.59                    47.57   \n",
       "2017-08-14                    47.57                     0.00   \n",
       "2017-08-15                     0.00                     0.00   \n",
       "\n",
       "            dcoilwtico_step_ahead_3  dcoilwtico_step_ahead_4  \\\n",
       "date                                                           \n",
       "2013-01-01                    93.12                    93.12   \n",
       "2013-01-02                    93.12                    93.20   \n",
       "2013-01-03                    93.20                    93.20   \n",
       "2013-01-04                    93.20                    93.21   \n",
       "2013-01-05                    93.21                    93.08   \n",
       "...                             ...                      ...   \n",
       "2017-08-11                    47.59                    47.57   \n",
       "2017-08-12                    47.57                     0.00   \n",
       "2017-08-13                     0.00                     0.00   \n",
       "2017-08-14                     0.00                     0.00   \n",
       "2017-08-15                     0.00                     0.00   \n",
       "\n",
       "            dcoilwtico_step_ahead_5  dcoilwtico_step_ahead_6  \\\n",
       "date                                                           \n",
       "2013-01-01                    93.20                    93.20   \n",
       "2013-01-02                    93.20                    93.21   \n",
       "2013-01-03                    93.21                    93.08   \n",
       "2013-01-04                    93.08                    93.81   \n",
       "2013-01-05                    93.81                    93.60   \n",
       "...                             ...                      ...   \n",
       "2017-08-11                     0.00                     0.00   \n",
       "2017-08-12                     0.00                     0.00   \n",
       "2017-08-13                     0.00                     0.00   \n",
       "2017-08-14                     0.00                     0.00   \n",
       "2017-08-15                     0.00                     0.00   \n",
       "\n",
       "            dcoilwtico_step_ahead_7  dcoilwtico_step_ahead_8  \\\n",
       "date                                                           \n",
       "2013-01-01                    93.21                    93.08   \n",
       "2013-01-02                    93.08                    93.81   \n",
       "2013-01-03                    93.81                    93.60   \n",
       "2013-01-04                    93.60                    93.60   \n",
       "2013-01-05                    93.60                    94.27   \n",
       "...                             ...                      ...   \n",
       "2017-08-11                     0.00                     0.00   \n",
       "2017-08-12                     0.00                     0.00   \n",
       "2017-08-13                     0.00                     0.00   \n",
       "2017-08-14                     0.00                     0.00   \n",
       "2017-08-15                     0.00                     0.00   \n",
       "\n",
       "            dcoilwtico_step_ahead_9  dcoilwtico_step_ahead_10  ...  \\\n",
       "date                                                           ...   \n",
       "2013-01-01                    93.81                     93.60  ...   \n",
       "2013-01-02                    93.60                     93.60  ...   \n",
       "2013-01-03                    93.60                     94.27  ...   \n",
       "2013-01-04                    94.27                     94.27  ...   \n",
       "2013-01-05                    94.27                     93.26  ...   \n",
       "...                             ...                       ...  ...   \n",
       "2017-08-11                     0.00                      0.00  ...   \n",
       "2017-08-12                     0.00                      0.00  ...   \n",
       "2017-08-13                     0.00                      0.00  ...   \n",
       "2017-08-14                     0.00                      0.00  ...   \n",
       "2017-08-15                     0.00                      0.00  ...   \n",
       "\n",
       "            54_SEAFOOD_step_ahead_7  54_SEAFOOD_step_ahead_8  \\\n",
       "date                                                           \n",
       "2013-01-01                      1.0                      1.0   \n",
       "2013-01-02                      1.0                      1.0   \n",
       "2013-01-03                      1.0                      0.0   \n",
       "2013-01-04                      0.0                      1.0   \n",
       "2013-01-05                      1.0                      5.0   \n",
       "...                             ...                      ...   \n",
       "2017-08-11                      0.0                      0.0   \n",
       "2017-08-12                      0.0                      0.0   \n",
       "2017-08-13                      0.0                      0.0   \n",
       "2017-08-14                      0.0                      0.0   \n",
       "2017-08-15                      0.0                      0.0   \n",
       "\n",
       "            54_SEAFOOD_step_ahead_9  54_SEAFOOD_step_ahead_10  \\\n",
       "date                                                            \n",
       "2013-01-01                      1.0                       0.0   \n",
       "2013-01-02                      0.0                       1.0   \n",
       "2013-01-03                      1.0                       5.0   \n",
       "2013-01-04                      5.0                       0.0   \n",
       "2013-01-05                      0.0                       2.0   \n",
       "...                             ...                       ...   \n",
       "2017-08-11                      0.0                       0.0   \n",
       "2017-08-12                      0.0                       0.0   \n",
       "2017-08-13                      0.0                       0.0   \n",
       "2017-08-14                      0.0                       0.0   \n",
       "2017-08-15                      0.0                       0.0   \n",
       "\n",
       "            54_SEAFOOD_step_ahead_11  54_SEAFOOD_step_ahead_12  \\\n",
       "date                                                             \n",
       "2013-01-01                       1.0                       5.0   \n",
       "2013-01-02                       5.0                       0.0   \n",
       "2013-01-03                       0.0                       2.0   \n",
       "2013-01-04                       2.0                       1.0   \n",
       "2013-01-05                       1.0                       2.0   \n",
       "...                              ...                       ...   \n",
       "2017-08-11                       0.0                       0.0   \n",
       "2017-08-12                       0.0                       0.0   \n",
       "2017-08-13                       0.0                       0.0   \n",
       "2017-08-14                       0.0                       0.0   \n",
       "2017-08-15                       0.0                       0.0   \n",
       "\n",
       "            54_SEAFOOD_step_ahead_13  54_SEAFOOD_step_ahead_14  \\\n",
       "date                                                             \n",
       "2013-01-01                       0.0                       2.0   \n",
       "2013-01-02                       2.0                       1.0   \n",
       "2013-01-03                       1.0                       2.0   \n",
       "2013-01-04                       2.0                       0.0   \n",
       "2013-01-05                       0.0                       1.0   \n",
       "...                              ...                       ...   \n",
       "2017-08-11                       0.0                       0.0   \n",
       "2017-08-12                       0.0                       0.0   \n",
       "2017-08-13                       0.0                       0.0   \n",
       "2017-08-14                       0.0                       0.0   \n",
       "2017-08-15                       0.0                       0.0   \n",
       "\n",
       "            54_SEAFOOD_step_ahead_15  54_SEAFOOD_step_ahead_16  \n",
       "date                                                            \n",
       "2013-01-01                       1.0                       2.0  \n",
       "2013-01-02                       2.0                       0.0  \n",
       "2013-01-03                       0.0                       1.0  \n",
       "2013-01-04                       1.0                       7.0  \n",
       "2013-01-05                       7.0                       0.0  \n",
       "...                              ...                       ...  \n",
       "2017-08-11                       0.0                       0.0  \n",
       "2017-08-12                       0.0                       0.0  \n",
       "2017-08-13                       0.0                       0.0  \n",
       "2017-08-14                       0.0                       0.0  \n",
       "2017-08-15                       0.0                       0.0  \n",
       "\n",
       "[1684 rows x 28928 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exog = pickle.load(\n",
    "    open('/home/nasibul/Desktop/e-commerce/Advanced ARIMA/Data/exog.pkl', 'rb'))\n",
    "X = pd.concat([exog, train], axis=1)\n",
    "Y = pd.DataFrame()\n",
    "for feature in X.columns:\n",
    "    for step in range(1, 17):\n",
    "        Y[f'{feature}_step_ahead_{step}'] = X[feature].shift(-step, fill_value=0)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1515, 1808, 1)\n",
      "(169, 1808, 1)\n",
      "(1515, 1808, 16)\n",
      "(169, 1808, 16)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.10, random_state=5, shuffle=False)\n",
    "X_test_copy = X_test\n",
    "X_test_index = X_test.index\n",
    "X_train = X_train.values.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = X_test.values.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "y_train = y_train.values.reshape(y_train.shape[0], X.shape[1], 16)\n",
    "y_test = y_test.values.reshape(y_test.shape[0], X.shape[1], 16)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = keras.models.Sequential([\n",
    "    keras.layers.LSTM(X.shape[1], return_sequences=True, input_shape=[X_train.shape[1], X_train.shape[2]]),\n",
    "    keras.layers.Dense(16, activation='relu')\n",
    "])\n",
    "lstm.compile(loss=keras.losses.MeanSquaredLogarithmicError(), optimizer=tf.keras.optimizers.Adam())\n",
    "lstm.summary()\n",
    "lstm.fit(X_train, y_train, epochs=200, callbacks=[es])\n",
    "pred_lstm = lstm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.DataFrame(pred_lstm[168].T, columns=X.columns, index=test.index.unique())\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pred.iloc[:, -1782:]\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = []\n",
    "sales = []\n",
    "for i in test.id:\n",
    "    row = test[test['id'] == i]\n",
    "    column = f\"{row['store_nbr'][0]}_{row['family'][0].replace('/', '_')}\"\n",
    "    value = pred[column][pred.index == row.index[0]][0]\n",
    "    # The info from the ID row is taken and used to form a variable called column. \n",
    "    # This column variable refers to the correct store in the dataframe and the equality check on the indexes refer to the proper dates lining up.\n",
    "    id.append(i)\n",
    "    sales.append(value)\n",
    "lstm_submission = pd.DataFrame({'id': id, 'sales': sales})\n",
    "lstm_submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
